{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v1_question_generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aweZgxXBDsOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a31b9b-3824-4826-ec2e-4407aa945b6d"
      },
      "source": [
        "!pip install -U transformers==3.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.8.0rc4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.1.96)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (4.62.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FARi6xuQ4IZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46ce827-89c9-45d4-b1cf-89af972c950e"
      },
      "source": [
        "!python -m nltk.downloader punkt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFldiKn8EIp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ead904-3f7a-4c82-c0fb-bfdf9db47ca8"
      },
      "source": [
        "!git clone https://github.com/patil-suraj/question_generation.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'question_generation' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAOgL63nEKIx"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re \n",
        "import csv\n",
        "import urllib.request as req\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lifeFNRx6mL",
        "outputId": "9b93c1e1-9ad7-45d9-909c-eaf01164d338"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLzyztEYzN6r"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/END-3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "0gjbpb4m9PcK",
        "outputId": "5dd5ff21-d9c4-47a9-a5df-d824ce323aeb"
      },
      "source": [
        "df = pd.read_excel('urlallocation.xlsx')\n",
        "teamurllist = []\n",
        "df['url']=df['url'].str.strip()\n",
        "for index, row in df.iterrows():\n",
        "    #print (row[\"url\"])\n",
        "    teamurllist.append(row[\"url\"])\n",
        "teamurllist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-46-88f96747795a>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    teamurllist(1:5)\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6A_qMxd-6Of",
        "outputId": "d4aac064-ccc2-4fad-fe38-35e80a8d672b"
      },
      "source": [
        "len(df['url'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0qTpSFpZ0mr"
      },
      "source": [
        "start_idx = 0\n",
        "end_idx = 1\n",
        "#end_idx = len(df['url'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE8sqwmXZ0is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb472cd-c205-441e-d6f8-49460ea2320b"
      },
      "source": [
        "\n",
        "uniqdict = {}\n",
        "qadict = {}\n",
        "\n",
        "#nlp = pipeline(\"question-generation\", model=\"valhalla/t5-base-qg-hl\")\n",
        "lengthlist = [512 , 1024, 2048 , 3072 , 4096]\n",
        "\n",
        "\n",
        "for url in teamurllist[start_idx:end_idx]:\n",
        "  #url = 'https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc' \n",
        "  # 'https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc'\n",
        "  #'https://pytorch.org/docs/stable/autograd.html'\n",
        "  # 'https://pytorch.org/docs/stable/generated/torch.load.html#torch.load'\n",
        "  print(url)\n",
        "  try:\n",
        "    html = req.urlopen(url).read()\n",
        "  except:\n",
        "    continue\n",
        "  soup = BeautifulSoup(html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  article = soup.find('article')\n",
        "  \n",
        "  if article:\n",
        "\n",
        "    sctns = article.find_all('div', class_=\"section\")\n",
        "\n",
        "    for sctn in sctns:\n",
        "      ptags = sctn.find_all('p')\n",
        "\n",
        "      \n",
        "      ptextlist = []\n",
        "\n",
        "      i = 1\n",
        "      for ptag in ptags:\n",
        "        ptextlist.append([ i , ptag.get_text(strip=True)])\n",
        "        i += 1\n",
        "\n",
        "      #print(ptextlist)\n",
        "\n",
        "      ptextlistlen = len(ptextlist)\n",
        "\n",
        "      ptextlt1024list = []\n",
        "      alltextdone = False\n",
        "\n",
        "      for j in range(40):\n",
        "        ptext = \"\"\n",
        "        if not alltextdone:\n",
        "\n",
        "          for k in range(j,ptextlistlen):\n",
        "          \n",
        "            arry = ptextlist[k]\n",
        "            #print(arry)\n",
        "            if len(ptext) + len(arry[1]) + 1 < 512: #1024:\n",
        "              ptext += arry[1]\n",
        "              ptext += ' '\n",
        "\n",
        "              if arry[0] == ptextlistlen:\n",
        "\n",
        "                #print('len 1',len(ptext))\n",
        "                try:\n",
        "                  listofdict = nlp(ptext)\n",
        "\n",
        "                  for qas in listofdict:\n",
        "                    qas['context'] = ptext\n",
        "                    qas['source'] = url\n",
        "                    qadict[qas['question']] = qas\n",
        "\n",
        "                except:\n",
        "                  1 == 1\n",
        "                \n",
        "                \n",
        "                try:\n",
        "                  listofdict = nlp_mtask(ptext)\n",
        "\n",
        "                  for qas in listofdict:\n",
        "                    qas['context'] = ptext\n",
        "                    qas['source'] = url\n",
        "                    qadict[qas['question']] = qas\n",
        "\n",
        "                except:\n",
        "                  1 == 1\n",
        "\n",
        "\n",
        "                alltextdone = True\n",
        "                break\n",
        "          \n",
        "            else:\n",
        "              \n",
        "              #print('len 2', '*'*40 , ptext , '*'*40, len(ptext))\n",
        "              try:\n",
        "                listofdict = nlp(ptext)\n",
        "\n",
        "                for qas in listofdict:\n",
        "                  #print(qas)\n",
        "                  qas['context'] = ptext\n",
        "                  qas['source'] = url\n",
        "\n",
        "                  qadict[qas['question']] = qas\n",
        "              except:\n",
        "                1 == 1\n",
        "              \n",
        "              try:\n",
        "                listofdict = nlp_mtask(ptext)\n",
        "\n",
        "                for qas in listofdict:\n",
        "                  qas['context'] = ptext\n",
        "                  qas['source'] = url\n",
        "                  qadict[qas['question']] = qas\n",
        "\n",
        "              except:\n",
        "                1 == 1\n",
        "            \n",
        "\n",
        "              break\n",
        "            \n",
        "        else:\n",
        "          break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://pytorch.org/docs/stable/generated/torch.bitwise_and.html#torch.bitwise_and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvBFbCVGELuW"
      },
      "source": [
        "## Single task QA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-NADwap0Eaf"
      },
      "source": [
        "text2 = \"\"\"PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.\n",
        "Features described in this documentation are classified by release status:\n",
        "Stable:  These features will be maintained long-term and there should generally\n",
        "be no major performance limitations or gaps in documentation.\n",
        "We also expect to maintain backwards compatibility (although\n",
        "breaking changes can happen and notice will be given one release ahead\n",
        "of time).\n",
        "Beta:  These features are tagged as Beta because the API may change based on\n",
        "user feedback, because the performance needs to improve, or because\n",
        "coverage across operators is not yet complete. For Beta features, we are\n",
        "committing to seeing the feature through to the Stable classification.\n",
        "We are not, however, committing to backwards compatibility.\n",
        "Prototype:  These features are typically not available as part of\n",
        "binary distributions like PyPI or Conda, except sometimes behind run-time\n",
        "flags, and are at an early stage for feedback and testing.\n",
        "Notes\n",
        "Language Bindings\n",
        "Python API\n",
        "Libraries\n",
        "Community\n",
        "Index\n",
        "Module Inde\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy_T1CiVVNuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9470b7df-bd75-4936-dbb1-db6ff66ca6f0"
      },
      "source": [
        "%cd question_generation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/question_generation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxoSS2_WEMvx"
      },
      "source": [
        "from pipelines import pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFSZiIc0StHY"
      },
      "source": [
        "nlp = pipeline(\"question-generation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZy5F8sjSv2W"
      },
      "source": [
        "#nlp(text3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DHB0dDqTb-o"
      },
      "source": [
        "If you want to use the t5-base model, then pass the path through model parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_050CddNTWeU"
      },
      "source": [
        "nlp = pipeline(\"question-generation\", model=\"valhalla/t5-base-qg-hl\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-Rd7yZmkQi8"
      },
      "source": [
        "nlp_mtask = pipeline(\"multitask-qa-qg\", model=\"valhalla/t5-base-qa-qg-hl\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDY-DUTrqnRU",
        "outputId": "0d5fe19f-be40-4060-802b-5fc74ef402e3"
      },
      "source": [
        "txt = \"\"\"Matrix product of two tensors.The behavior depends on the dimensionality of the tensors as follows:If both tensors are 1-dimensional, the dot product (scalar) is returned.If both arguments are 2-dimensional, the matrix-matrix product is returned.If the first argument is 1-dimensional and the second argument is 2-dimensional,\n",
        "a 1 is prepended to its dimension for the purpose of the matrix multiply.\n",
        "After the matrix multiply, the prepended dimension is removed.If the first argument is 2-dimensional and the second argument is 1-dimensional,\n",
        "the matrix-vector product is returned.If both arguments are at least 1-dimensional and at least one argument is\n",
        "N-dimensional (where N > 2), then a batched matrix multiply is returned.  If the first\n",
        "argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the\n",
        "batched matrix multiply and removed after.  If the second argument is 1-dimensional, a\n",
        "1 is appended to its dimension for the purpose of the batched matrix multiple and removed after.The non-matrix (i.e. )\"\"\"\n",
        "\n",
        "\"\"\"# is appended to its dimension for the purpose of the batched matrix multiple and removed after.\n",
        "The non-matrix (i.e. batch) dimensions arebroadcasted(and thus\n",
        "must be broadcastable).\"\"\"\n",
        "\n",
        "nlp(txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answer': 'Matrix product of two tensors',\n",
              "  'question': 'What is the behavior dependent on the dimensionality of the tensors?'},\n",
              " {'answer': 'the matrix multiply',\n",
              "  'question': 'When is the prepended dimension removed?'},\n",
              " {'answer': 'batched matrix multiply',\n",
              "  'question': 'If the first argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of what?'},\n",
              " {'answer': 'non-matrix',\n",
              "  'question': 'What is another term for a matrix product of two tensors?'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJDsvgjVrKIg",
        "outputId": "e3f73eb8-2ce5-4087-9007-955cca44e77a"
      },
      "source": [
        "len(txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1032"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3stIEi9XkaHx"
      },
      "source": [
        "### 512 length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc48Q2VGQPIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516ca9c1-2464-422d-af94-377cf87fc4ef"
      },
      "source": [
        "uniqdict = {}\n",
        "qadict = {}\n",
        "\n",
        "#nlp = pipeline(\"question-generation\", model=\"valhalla/t5-base-qg-hl\")\n",
        "lengthlist = [512 , 1024, 2048 , 3072 , 4096]\n",
        "\n",
        "\n",
        "for url in teamurllist[start_idx:end_idx]:\n",
        "  #url = 'https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc' \n",
        "  # 'https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc'\n",
        "  #'https://pytorch.org/docs/stable/autograd.html'\n",
        "  # 'https://pytorch.org/docs/stable/generated/torch.load.html#torch.load'\n",
        "  #print(url)\n",
        "  try:\n",
        "    html = req.urlopen(url).read()\n",
        "    #print(html)\n",
        "  except:\n",
        "    continue\n",
        "  soup = BeautifulSoup(html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  article = soup.find('article')\n",
        "  \n",
        "  if article:\n",
        "    \n",
        "\n",
        "    sctns = article.find_all('div', class_=\"section\")\n",
        "\n",
        "    for sctn in sctns:\n",
        "      ptags = sctn.find_all('p')\n",
        "\n",
        "      \n",
        "      ptextlist = []\n",
        "\n",
        "      i = 1\n",
        "      for ptag in ptags:\n",
        "        ptextlist.append([ i , ptag.get_text(strip=True)])\n",
        "        i += 1\n",
        "\n",
        "      #print(ptextlist)\n",
        "\n",
        "      ptextlistlen = len(ptextlist)\n",
        "      print(ptextlistlen)\n",
        "\n",
        "      ptextlt1024list = []\n",
        "      alltextdone = False\n",
        "\n",
        "      for j in range(40):\n",
        "        ptext = \"\"\n",
        "        if not alltextdone:\n",
        "\n",
        "          for k in range(j,ptextlistlen):\n",
        "          \n",
        "            arry = ptextlist[k]\n",
        "            #print(arry)\n",
        "            if len(ptext) + len(arry[1]) + 1 < 512: #1024:\n",
        "              ptext += arry[1]\n",
        "              ptext += ' '\n",
        "\n",
        "              if arry[0] == ptextlistlen:\n",
        "\n",
        "                #print('len 1',len(ptext))\n",
        "                try:\n",
        "                  listofdict = nlp(ptext)\n",
        "\n",
        "                  for qas in listofdict:\n",
        "                    qas['context'] = ptext\n",
        "                    qas['source'] = url\n",
        "                    qadict[qas['question']] = qas\n",
        "\n",
        "                except:\n",
        "                  1 == 1\n",
        "                \n",
        "                \n",
        "                try:\n",
        "                  listofdict = nlp_mtask(ptext)\n",
        "\n",
        "                  for qas in listofdict:\n",
        "                    qas['context'] = ptext\n",
        "                    qas['source'] = url\n",
        "                    qadict[qas['question']] = qas\n",
        "\n",
        "                except:\n",
        "                  1 == 1\n",
        "\n",
        "\n",
        "                alltextdone = True\n",
        "                break\n",
        "          \n",
        "            else:\n",
        "              \n",
        "              #print('len 2', '*'*40 , ptext , '*'*40, len(ptext))\n",
        "              try:\n",
        "                listofdict = nlp(ptext)\n",
        "\n",
        "                for qas in listofdict:\n",
        "                  #print(qas)\n",
        "                  qas['context'] = ptext\n",
        "                  qas['source'] = url\n",
        "\n",
        "                  qadict[qas['question']] = qas\n",
        "              except:\n",
        "                1 == 1\n",
        "              \n",
        "              try:\n",
        "                listofdict = nlp_mtask(ptext)\n",
        "\n",
        "                for qas in listofdict:\n",
        "                  qas['context'] = ptext\n",
        "                  qas['source'] = url\n",
        "                  qadict[qas['question']] = qas\n",
        "\n",
        "              except:\n",
        "                1 == 1\n",
        "            \n",
        "\n",
        "              break\n",
        "            \n",
        "        else:\n",
        "          break\n",
        "     \n",
        "          \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "OccV2LQnAfpf",
        "outputId": "8200ea6a-fd18-4b05-d444-74273e14870d"
      },
      "source": [
        "qas['context']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-b837ef48184e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'qas' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXCmtHOMRfxC"
      },
      "source": [
        "k = 0\n",
        "for v in qadict.values():\n",
        "  print( k , '*'*40,'\\n question :-' , v['question'] ,'\\n answer:-' , v['answer'] ,'\\n context:-' , v['context'] ,'\\n source:-' , v['source'])\n",
        "  k += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBYhwYeslI1K"
      },
      "source": [
        "### 1024 length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px6v-bKOTy87"
      },
      "source": [
        "uniqdict = {}\n",
        "qadict_1024 = {}\n",
        "\n",
        "#nlp = pipeline(\"question-generation\", model=\"valhalla/t5-base-qg-hl\")\n",
        "lengthlist = [512 , 1024, 2048 , 3072 , 4096]\n",
        "\n",
        "\n",
        "for url in teamurllist[start_idx:end_idx]:\n",
        "  #url = 'https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc' \n",
        "  # 'https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc'\n",
        "  #'https://pytorch.org/docs/stable/autograd.html'\n",
        "  # 'https://pytorch.org/docs/stable/generated/torch.load.html#torch.load'\n",
        "  #print(url)\n",
        "  try:\n",
        "    html = req.urlopen(url).read()\n",
        "  except:\n",
        "    continue\n",
        "  soup = BeautifulSoup(html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  article = soup.find('article')\n",
        "  \n",
        "  if article:\n",
        "\n",
        "    sctns = article.find_all('div', class_=\"section\")\n",
        "\n",
        "    for sctn in sctns:\n",
        "      ptags = sctn.find_all('p')\n",
        "\n",
        "      \n",
        "      ptextlist = []\n",
        "\n",
        "      i = 1\n",
        "      for ptag in ptags:\n",
        "        ptextlist.append([ i , ptag.get_text(strip=True)])\n",
        "        i += 1\n",
        "\n",
        "      #print(ptextlist)\n",
        "\n",
        "      ptextlistlen = len(ptextlist)\n",
        "\n",
        "      ptextlt1024list = []\n",
        "      alltextdone = False\n",
        "\n",
        "      for j in range(40):\n",
        "        ptext = \"\"\n",
        "        if not alltextdone:\n",
        "\n",
        "          for k in range(j,ptextlistlen):\n",
        "          \n",
        "            arry = ptextlist[k]\n",
        "            #print(arry)\n",
        "            if len(ptext) + len(arry[1]) + 1 < 1024:\n",
        "              ptext += arry[1]\n",
        "              ptext += ' '\n",
        "\n",
        "              if arry[0] == ptextlistlen:\n",
        "\n",
        "                #print('len 1',len(ptext))\n",
        "                try:\n",
        "                  listofdict = nlp(ptext)\n",
        "\n",
        "                  for qas in listofdict:\n",
        "                    qas['context'] = ptext\n",
        "                    qas['source'] = url\n",
        "                    qadict_1024[qas['question']] = qas\n",
        "\n",
        "                except:\n",
        "                  1 == 1\n",
        "\n",
        "                try:\n",
        "                  listofdict = nlp_mtask(ptext)\n",
        "\n",
        "                  for qas in listofdict:\n",
        "                    qas['context'] = ptext\n",
        "                    qas['source'] = url\n",
        "                    qadict[qas['question']] = qas\n",
        "\n",
        "                except:\n",
        "                  1 == 1\n",
        "\n",
        "              \n",
        "                alltextdone = True\n",
        "                break\n",
        "          \n",
        "            else:\n",
        "              \n",
        "              #print('len 2', '*'*40 , ptext , '*'*40, len(ptext))\n",
        "              try:\n",
        "                listofdict = nlp(ptext)\n",
        "\n",
        "                for qas in listofdict:\n",
        "                  #print(qas)\n",
        "                  qas['context'] = ptext\n",
        "                  qas['source'] = url\n",
        "\n",
        "                  qadict_1024[qas['question']] = qas\n",
        "              except:\n",
        "                1 == 1\n",
        "              \n",
        "              try:\n",
        "                listofdict = nlp_mtask(ptext)\n",
        "\n",
        "                for qas in listofdict:\n",
        "                  qas['context'] = ptext\n",
        "                  qas['source'] = url\n",
        "                  qadict[qas['question']] = qas\n",
        "\n",
        "              except:\n",
        "                1 == 1\n",
        "\n",
        "            \n",
        "              break\n",
        "            \n",
        "        else:\n",
        "          break\n",
        "     \n",
        "          \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IklVYjH3lRR6"
      },
      "source": [
        "### 2048 length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8lkv29QgHPv"
      },
      "source": [
        "uniqdict = {}\n",
        "qadict_2048 = {}\n",
        "\n",
        "#nlp = pipeline(\"question-generation\", model=\"valhalla/t5-base-qg-hl\")\n",
        "lengthlist = [512 , 1024, 2048 , 3072 , 4096]\n",
        "\n",
        "\n",
        "for url in teamurllist[start_idx:end_idx]:\n",
        "  #url = 'https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc' \n",
        "  # 'https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc'\n",
        "  #'https://pytorch.org/docs/stable/autograd.html'\n",
        "  # 'https://pytorch.org/docs/stable/generated/torch.load.html#torch.load'\n",
        "  #print(url)\n",
        "  try:\n",
        "    html = req.urlopen(url).read()\n",
        "  except:\n",
        "    continue\n",
        "  soup = BeautifulSoup(html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  article = soup.find('article')\n",
        "  \n",
        "  if article:\n",
        "\n",
        "    sctns = article.find_all('div', class_=\"section\")\n",
        "\n",
        "    for sctn in sctns:\n",
        "      ptags = sctn.find_all('p')\n",
        "\n",
        "      \n",
        "      ptextlist = []\n",
        "\n",
        "      i = 1\n",
        "      for ptag in ptags:\n",
        "        ptextlist.append([ i , ptag.get_text(strip=True)])\n",
        "        i += 1\n",
        "\n",
        "      #print(ptextlist)\n",
        "\n",
        "      ptextlistlen = len(ptextlist)\n",
        "\n",
        "      ptextlt1024list = []\n",
        "      alltextdone = False\n",
        "\n",
        "      for j in range(40):\n",
        "        ptext = \"\"\n",
        "        if not alltextdone:\n",
        "\n",
        "          for k in range(j,ptextlistlen):\n",
        "          \n",
        "            arry = ptextlist[k]\n",
        "            #print(arry)\n",
        "            if len(ptext) + len(arry[1]) + 1 < 2*1024:\n",
        "              ptext += arry[1]\n",
        "              ptext += ' '\n",
        "\n",
        "              if arry[0] == ptextlistlen:\n",
        "\n",
        "                #print('len 1',len(ptext))\n",
        "                try:\n",
        "                  listofdict = nlp(ptext)\n",
        "\n",
        "                  for qas in listofdict:\n",
        "                    qas['context'] = ptext\n",
        "                    qas['source'] = url\n",
        "                    qadict_2048[qas['question']] = qas\n",
        "\n",
        "                except:\n",
        "                  1 == 1\n",
        "                \n",
        "                try:\n",
        "                  listofdict = nlp_mtask(ptext)\n",
        "\n",
        "                  for qas in listofdict:\n",
        "                    qas['context'] = ptext\n",
        "                    qas['source'] = url\n",
        "                    qadict[qas['question']] = qas\n",
        "\n",
        "                except:\n",
        "                  1 == 1\n",
        "\n",
        "              \n",
        "                alltextdone = True\n",
        "                break\n",
        "          \n",
        "            else:\n",
        "              \n",
        "              #print('len 2', '*'*40 , ptext , '*'*40, len(ptext))\n",
        "              try:\n",
        "                listofdict = nlp(ptext)\n",
        "\n",
        "                for qas in listofdict:\n",
        "                  #print(qas)\n",
        "                  qas['context'] = ptext\n",
        "                  qas['source'] = url\n",
        "\n",
        "                  qadict_2048[qas['question']] = qas\n",
        "              except:\n",
        "                1 == 1\n",
        "              try:\n",
        "                listofdict = nlp_mtask(ptext)\n",
        "\n",
        "                for qas in listofdict:\n",
        "                  qas['context'] = ptext\n",
        "                  qas['source'] = url\n",
        "                  qadict[qas['question']] = qas\n",
        "\n",
        "              except:\n",
        "                1 == 1\n",
        "              \n",
        "            \n",
        "              break\n",
        "            \n",
        "        else:\n",
        "          break\n",
        "     \n",
        "          \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ROlveBJRxgO"
      },
      "source": [
        "\n",
        "k = 0\n",
        "for v in qadict.values():\n",
        "  print( k , '*'*40,'\\n question :-' , v['question'] ,'\\n answer:-' , v['answer'] ,'\\n context:-' , v['context'] ,'\\n source:-' , v['source'])\n",
        "  k += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o190LjvEBW-M"
      },
      "source": [
        "k = 0\n",
        "for v in qadict_1024.values():\n",
        "  print( k , '*'*40,'\\n question :-' , v['question'] ,'\\n answer:-' , v['answer'] ,'\\n context:-' , v['context'] ,'\\n source:-' , v['source'])\n",
        "  k += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfoxL1V7gPpE"
      },
      "source": [
        "\n",
        "k = 0\n",
        "for v in qadict_2048.values():\n",
        "  print( k , '*'*40,'\\n question :-' , v['question'] ,'\\n answer:-' , v['answer'] ,'\\n context:-' , v['context'] ,'\\n source:-' , v['source'])\n",
        "  k += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H19RaUCYR_61",
        "outputId": "907c6667-254b-4a7d-d343-7a09cdbbee7e"
      },
      "source": [
        "combkeys = list(qadict.keys()) + list(set(qadict.keys()) - set(qadict_1024.keys()))\n",
        "\n",
        "combkeys123 = combkeys + list(set(combkeys) - set(qadict_2048.keys()))\n",
        "\n",
        "len(combkeys123) , len(combkeys) , len(qadict.keys()), len(qadict_1024.keys()) , len(qadict_2048.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 149, 83, 21, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO4SDg-cftKf",
        "outputId": "5f16f913-b4da-40fd-eb75-ab3e25fce90a"
      },
      "source": [
        "onelist = {}\n",
        "for key in combkeys123:\n",
        "  if key in qadict_2048:\n",
        "    onelist[key] = qadict_2048[key]\n",
        "  elif key in qadict_1024:\n",
        "    onelist[key] = qadict_1024[key]\n",
        "  elif key in qadict:\n",
        "    onelist[key] = qadict[key]\n",
        "\n",
        "len(onelist)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKPEJm-CixRX"
      },
      "source": [
        "\n",
        "with open('/content/onlytextpytorch.json', 'w') as file:\n",
        "  file.write(json.dumps(onelist, indent=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egRuC8QFUy0v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uiG6_NQVCIz"
      },
      "source": [
        "## Multitask QA-QG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_PKMG28VhxM"
      },
      "source": [
        "### small-model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAkVmsH9VEIu"
      },
      "source": [
        "nlp2 = pipeline(\"multitask-qa-qg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dRiLecTVk8E"
      },
      "source": [
        "#### QG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKA65C51VLGu"
      },
      "source": [
        "nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAAxbcwzVXlV"
      },
      "source": [
        "nlp2(text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a81EN_WWVpae"
      },
      "source": [
        "nlp2(text4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9c2CkhhVsxs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuOL3X_XV28R"
      },
      "source": [
        "#### QA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe-v3I8aV4En"
      },
      "source": [
        "nlp2({\n",
        "  \"question\": \"Who created Python ?\",\n",
        "  \"context\": text\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZchZFXPuWI62"
      },
      "source": [
        "nlp2({\n",
        "    \"question\": \"Who wrote Forrest Gump ?\",\n",
        "     \"context\": text4\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARBRwBj5WVga"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEk-EU9UWaBr"
      },
      "source": [
        "### base-model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx1KjJzaWa-a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL5Cgm2XWikl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwCA0sjtWldK"
      },
      "source": [
        "#### QG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwby-LJpWldj"
      },
      "source": [
        "nlp2(text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YIZtVu8Wldw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh46cnicWld1"
      },
      "source": [
        "#### QA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ew7vRA2Wld6"
      },
      "source": [
        "\"\"\"nlp({\n",
        "    \"question\": \"Who wrote Forrest Gump ?\",\n",
        "     \"context\": text4\n",
        "})\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CkkYm6aWld-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Wq-2nuXDvl"
      },
      "source": [
        "## End-to-End QG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS4XfQh0X3W8"
      },
      "source": [
        "### small model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzJjXzpmXG7t"
      },
      "source": [
        "nlp3 = pipeline(\"e2e-qg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd_2-fvYXaXb"
      },
      "source": [
        "nlp3(text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDo01sKdXjfG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNBlsV_eX9mm"
      },
      "source": [
        "### base-model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5oUJ5_0X_Je"
      },
      "source": [
        "nlp4 = pipeline(\"e2e-qg\", model=\"valhalla/t5-base-e2e-qg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42YUWV1Dnhfb"
      },
      "source": [
        "s "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWzd3JFQYI2O"
      },
      "source": [
        "nlp4(text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMY7ZLdYYUkL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}